services:
  # Backend API Service
  backend:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile.backend
    container_name: bmi-chat-backend
    restart: unless-stopped
    ports:
      - "3006:3006"
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - API_HOST=0.0.0.0
      - API_PORT=3006
      - API_WORKERS=2
      - CORS_ORIGINS=["http://localhost:3003", "http://frontend:3003"]
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.0}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-2000}
      - SECRET_KEY=${SECRET_KEY}
      - DATABASE_URL=sqlite:///data/sqlite/bmi_chat.db
      - VECTOR_DB_PATH=data/vectors
      - UPLOAD_DIR=data/uploads
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FILE=logs/app.log
    volumes:
      - backend_data:/app/data
      - backend_logs:/app/logs
    networks:
      - bmi-chat-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:3006/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend Service
  frontend:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile.frontend
    container_name: bmi-chat-frontend
    restart: unless-stopped
    ports:
      - "3003:3003"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - bmi-chat-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Nginx Reverse Proxy (Optional - for production-like setup)
  nginx:
    image: nginx:alpine
    container_name: bmi-chat-nginx
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./nginx-proxy.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - frontend
      - backend
    networks:
      - bmi-chat-network
    profiles:
      - production

volumes:
  backend_data:
    driver: local
  backend_logs:
    driver: local

networks:
  bmi-chat-network:
    driver: bridge
